{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Employment-Unemployment Model\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Goal**:\n",
    "\n",
    "Estimate a Markov chain using employment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Steps to \"understanding the world around us\" (a short digression)\n",
    "\n",
    "\n",
    "Our friend Jim Savage has developed what he calls a \"modern statistical workflow\" for understanding the world around us. We summarize (a subset) of his steps below:\n",
    "\n",
    "> 1. Prepare and visualize your data.\n",
    "> 2. Create a generative model for the data...\n",
    ">   - The first model created should be as simple as possible.\n",
    "> 3. Simulate some “fake data” from your model given some parameters that you \"pick out of a hat\"\n",
    "> 4. Fit your model to the fake data and check for the quality of the fit\n",
    "> 5. Check that you were able to capture these “known unknowns”.\n",
    ">   - Possibly repeat 3-5 with different methods and parameters, to get an understanding of how well the fitting procedure works\n",
    "> 6. Fit the model to your real data, check the fit\n",
    "> 7. Argue about the results with your friends and colleagues\n",
    "> 8. Go back to 2. with a slightly richer model. Repeat.\n",
    "> 9. Think carefully about what decisions will be made from the analysis, encode a loss function, and perform statistical decision analysis.\n",
    "\n",
    "Later this semester, we will talk extensively about what it means to \"fit\" your model (and all of the work that it entails), but, for now, we find it sufficient to say that it's a process to help your model line up with the data that you're working to understand.\n",
    "\n",
    "We'll do a version of steps 1-6 to help us improve our understanding of the labor data that we previously saw."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Our plan\n",
    "\n",
    "1. Skip -- We've previously prepared and visualized our data.\n",
    "2. Develop a generative model of employment and unemployment\n",
    "3. Simulate data from our generative model for given parameters\n",
    "4. Fit our model to the simulated data\n",
    "5. Explore different ways that we might have chosen to fit the data\n",
    "6. Fit the model with the BLS data\n",
    "7. Examine what our model implies for the effects of COVID on employment/unemployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Develop a generative model\n",
    "\n",
    "**A simple model of employment**\n",
    "\n",
    "In the vein of, \"the first model created should be as simple as possible\", we revisit the unemployment model that we have previously discussed.\n",
    "\n",
    "Consider a single individual that transitions between employment and unemployment\n",
    "\n",
    "* When employed, they lose their job with probability $\\beta$\n",
    "* When unemployed, they find a new job with probability $\\alpha$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![ModelFlowchart](model_diagram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Simulate data from our generative model\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "We will break simulating data from this model into two steps:\n",
    "\n",
    "1. Given today's state and the transition probabilities, draw from tomorrow's state\n",
    "2. Given an initial state and transition probabilities, simulate an entire history of employment/unemployment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulate the one-step employment transition**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def next_state(s_t, alpha, beta):\n",
    "    \"\"\"\n",
    "    Transitions from employment/unemployment in period t to\n",
    "    employment/unemployment in period t+1\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    s_t : int\n",
    "        The individual's current state... s_t = 0 maps to\n",
    "        unemployed and s_t = 1 maps to employed\n",
    "    alpha : float\n",
    "        The probability that an individual goes from\n",
    "        unemployed to employed\n",
    "    beta : float\n",
    "        The probability that an individual goes from\n",
    "        employed to unemployed\n",
    "    \"\"\"\n",
    "    # Draw a random number\n",
    "    u_t = np.random.rand()\n",
    "\n",
    "    # Let 0 be unemployed... If unemployed and draws\n",
    "    # a value less than lambda then becomes employed\n",
    "    if (s_t == 0) and (u_t < alpha):\n",
    "        s_tp1 = 1\n",
    "    # Let 1 be employed... If employed and draws a\n",
    "    # value less than beta then becomes unemployed\n",
    "    elif (s_t == 1) and (u_t < beta):\n",
    "        s_tp1 = 0\n",
    "    # Otherwise, he keeps the same state as he had\n",
    "    # at period t\n",
    "    else:\n",
    "        s_tp1 = s_t\n",
    "\n",
    "    return s_tp1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Notice how this function depends on the Markov property!\n",
    "\n",
    "The Markov property says $\\text{Probability}(s_{t+1} | s_{t}) = \\text{Probability}(s_{t+1} | s_{t}, s_{t-1}, \\dots, s_0)$.\n",
    "\n",
    "This means that, other than the transition probabilities, we only need to give the function the previous state and not the entire history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Testing our function**\n",
    "\n",
    "It's always a good idea to write some simple test cases for functions that you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should always transition to employment from unemployment\n",
    "# when alpha is 1\n",
    "next_state(0, 1.0, 0.5) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should always transition to unemployment from employment\n",
    "# when beta is 1\n",
    "next_state(1, 0.5, 1.0) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulate entire history**\n",
    "\n",
    "**Note**: We will eventually allow $\\alpha$ and $\\beta$ to change over time, so, while we want you think of them as constant for now, we will be writing the code in a way that allows for them to fluctate period-by-period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_employment_history(alpha, beta, s_0):\n",
    "    \"\"\"\n",
    "    Simulates the history of employment/unemployment. It\n",
    "    will simulate as many periods as elements in `alpha`\n",
    "    and `beta`\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : np.array(float, ndim=1)\n",
    "        The probability that an individual goes from\n",
    "        unemployed to employed\n",
    "    beta : np.array(float, ndim=1)\n",
    "        The probability that an individual goes from\n",
    "        employed to unemployed\n",
    "    s_0 : int\n",
    "        The initial state of unemployment/employment, which\n",
    "        should take value of 0 (unemployed) or 1 (employed)\n",
    "    \"\"\"\n",
    "    # Create array to hold the values of our simulation\n",
    "    assert(len(alpha) == len(beta))\n",
    "    T = len(alpha)\n",
    "    s_hist = np.zeros(T+1, dtype=int)\n",
    "\n",
    "    s_hist[0] = s_0\n",
    "    for t in range(T):\n",
    "        # Step one period into the future\n",
    "        s_0 = next_state(s_0, alpha[t], beta[t])  # Notice alpha[t] and beta[t]\n",
    "        s_hist[t+1] = s_0\n",
    "\n",
    "    return s_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Check output of the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = np.ones(50)*0.25\n",
    "beta = np.ones(50)*0.025\n",
    "\n",
    "simulate_employment_history(alpha, beta, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 4: Fit your model to the fake data\n",
    "\n",
    "There are lots of procedures that one could use to map the data into the implied parameters of your model, but we're going to proceed by simply counting the \"frequencies of transitions\"\n",
    "\n",
    "Let's think about the general case. Consider an $N$-state Markov chain. The parameters of the Markov chain are the elements of the transition matrix, $P$.\n",
    "\n",
    "$$P \\equiv \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\end{bmatrix}$$\n",
    "\n",
    "Let $\\{y_0, y_1, \\dots, y_T\\}$ be a sequence of observations generated from the $N$-state Markov chain, then our \"fitting\" procedure would assign the following value to $p_{ij}$:\n",
    "\n",
    "$$p_{ij} = \\frac{\\sum_{t=0}^T \\mathbb{1}_{y_{t} == i} \\mathbb{1}_{y_{t+1} == j}}{\\sum_{t=0}^T \\mathbb{1}_{y_{t} == i}}$$\n",
    "\n",
    "**Note**: If you'd like to understand why this procedure makes sense, we recommend computing $\\sum_{j=1}^N p_{ij}$ for a given $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Counting frequencies**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def count_frequencies_individual(history):\n",
    "    \"\"\"\n",
    "    Computes the transition probabilities for a two-state\n",
    "    Markov chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : np.array(int, ndim=1)\n",
    "        An array with the state values of a two-state Markov chain\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    alpha : float\n",
    "        The probability of transitioning from state 0 to 1\n",
    "    beta : float\n",
    "        The probability of transitioning from state 1 to 0\n",
    "    \"\"\"\n",
    "    # Get length of the simulation and an index tracker\n",
    "    T = len(history)\n",
    "    idx = np.arange(T)\n",
    "\n",
    "    # Determine when the chain had values 0 and 1 -- Notice\n",
    "    # that we can't use the last value because we don't see\n",
    "    # where it transitions to\n",
    "    zero_idxs = idx[(history == 0) & (idx < T-1)]\n",
    "    one_idxs = idx[(history == 1) & (idx < T-1)]\n",
    "\n",
    "    # Check what percent of the t+1 values were 0/1\n",
    "    alpha = np.sum(history[zero_idxs+1]) / len(zero_idxs)\n",
    "    beta = np.sum(1 - history[one_idxs+1]) / len(one_idxs)\n",
    "\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Checking the fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def check_accuracy(T, alpha=0.25, beta=0.025):\n",
    "    \"\"\"\n",
    "    Checks the accuracy of our fit by printing the true values\n",
    "    and the fitted values for a given T\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : int\n",
    "        The length of our simulation\n",
    "    alpha : float\n",
    "        The probability that an individual goes from\n",
    "        unemployed to employed\n",
    "    beta : float\n",
    "        The probability that an individual goes from\n",
    "        employed to unemployed\n",
    "    \"\"\"\n",
    "    idx = np.arange(T)\n",
    "    alpha_np = np.ones(T)*alpha\n",
    "    beta_np = np.ones(T)*beta\n",
    "\n",
    "    # Simulate a sample history\n",
    "    emp_history = simulate_employment_history(alpha_np, beta_np, 0)\n",
    "\n",
    "    # Check the fit\n",
    "    alpha_hat, beta_hat = count_frequencies_individual(emp_history)\n",
    "    \n",
    "    print(f\"True alpha was {alpha} and fitted value was {alpha_hat}\")\n",
    "    print(f\"True beta was {beta} and fitted value was {beta_hat}\")\n",
    "    \n",
    "    return alpha, alpha_hat, beta, beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha was 0.25 and fitted value was 0.25452196382428943\n",
      "True beta was 0.025 and fitted value was 0.021244309559939303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.25452196382428943, 0.025, 0.021244309559939303)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(10_000, 0.25, 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Well... If we observe 10,000 months of employment history for someone then we know that we can back out the parameters of our models... Unfortunately, this is unlikely to be what our data contains..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What about for an entire lifetime of employment transitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha was 0.25 and fitted value was 0.2631578947368421\n",
      "True beta was 0.025 and fitted value was 0.028985507246376812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.2631578947368421, 0.025, 0.028985507246376812)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(45*12, 0.25, 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What about for just two years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True alpha was 0.25 and fitted value was 0.3333333333333333\n",
      "True beta was 0.025 and fitted value was 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25, 0.3333333333333333, 0.025, 0.0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(2*12, 0.25, 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3 and 4 (second try)\n",
    "\n",
    "Generating data for a single individual will not give us a good chance of fitting our model accurately...\n",
    "\n",
    "The BLS isn't basing their EU/UE rates off of a single individual, rather, they're using an entire cross-section of individuals!\n",
    "\n",
    "Can we use a cross-section rather than a single history?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes, but, in order for a version of our \"frequency counting\" procedure to work, we need independence across individuals, i.e.\n",
    "\n",
    "$$\\text{Probability}(s_{i, t+1}, s_{j, t+1} | s_{i, t}, s_{j, t}, \\alpha, \\beta) = \\text{Probability}(s_{i, t+1} | s_{i, t}, \\alpha, \\beta) \\text{Probability}(s_{j, t+1} | s_{j, t}, \\alpha, \\beta)$$\n",
    "\n",
    "In the previous case when we only had a single individual, the Markov property did a lot of the work to get independence for us.\n",
    "\n",
    "When might this not be the case?\n",
    "\n",
    "* Change in government policy results in a \"jobs guarantee\"\n",
    "* Technological change results in the destruction of an entire industries jobs\n",
    "* Recession causes increased firing across entire country\n",
    "\n",
    "(Spoiler alert: Some of these might present problems for us... which is why we'll allow for $\\alpha$ and $\\beta$ to move each period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulating a cross-section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_employment_cross_section(alpha, beta, s_0, N=500):\n",
    "    \"\"\"\n",
    "    Simulates a cross-section of employment/unemployment using\n",
    "    the model we've described above.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : np.array(float, ndim=1)\n",
    "        The probability that an individual goes from\n",
    "        unemployed to employed\n",
    "    beta : np.array(float, ndim=1)\n",
    "        The probability that an individual goes from\n",
    "        employed to unemployed\n",
    "    s_0 : np.array(int, ndim=1)\n",
    "        The fraction of the population that begins in each\n",
    "        employment state\n",
    "    N : int\n",
    "        The number of individuals in our cross-section\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    s_hist_cs : np.array(int, ndim=2)\n",
    "        An `N x T` matrix that contains an individual\n",
    "        history of employment along each row\n",
    "    \"\"\"\n",
    "    # Make sure transitions are same size and get the length\n",
    "    # of the simulation from the length of the transition\n",
    "    # probabilities\n",
    "    assert(len(alpha) == len(beta))\n",
    "    T = len(alpha)\n",
    "\n",
    "    # Check the fractions add to one and figure out how many\n",
    "    # zeros we should have\n",
    "    assert(np.abs(np.sum(s_0) - 1.0) < 1e-8)\n",
    "    Nz = np.floor(s_0[0]*N).astype(int)\n",
    "\n",
    "    # Allocate space to store the simulations\n",
    "    s_hist_cs = np.zeros((N, T+1), dtype=int)\n",
    "    s_hist_cs[Nz:, 0] = 1\n",
    "    \n",
    "    for i in range(N):\n",
    "        s_hist_cs[i, :] = simulate_employment_history(\n",
    "            alpha, beta, s_hist_cs[i, 0]\n",
    "        )\n",
    "    \n",
    "    return s_hist_cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "alpha = np.ones(1)*0.25\n",
    "beta = np.ones(1)*0.025\n",
    "\n",
    "simulate_employment_cross_section(alpha, beta, np.array([0.25, 0.75]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Store the simulation in pandas**\n",
    "\n",
    "Our data will typically be stored in a DataFrame, so let's keep our simulated data in a DataFrame as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_employment_cross_section(eu_ue_df, s_0, N=500):\n",
    "    \"\"\"\n",
    "    Simulate a cross-section of employment experiences\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eu_ue_df : pd.DataFrame\n",
    "        A DataFrame with columns `dt`, `alpha`, and `beta`\n",
    "        that have the monthly eu/ue transition rates\n",
    "    s_0 : np.array(float, ndim=1)\n",
    "        The fraction of the population that begins in each\n",
    "        employment state\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        A DataFrame with the dates and an employment outcome\n",
    "        associated with each date of `eu_ue_df`\n",
    "    \"\"\"\n",
    "    # Make sure that `ue_ue_df` is sorted by date\n",
    "    eu_ue_df = eu_ue_df.sort_values(\"dt\")\n",
    "    alpha = eu_ue_df[\"alpha\"].to_numpy()\n",
    "    beta = eu_ue_df[\"beta\"].to_numpy()\n",
    "\n",
    "    # Simulate cross-section\n",
    "    employment_history = simulate_employment_cross_section(\n",
    "        alpha, beta, s_0, N\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(employment_history[:, :-1].T)\n",
    "    df = pd.concat([eu_ue_df, df], axis=1)\n",
    "    df = pd.melt(\n",
    "        df, id_vars=[\"dt\", \"alpha\", \"beta\"],\n",
    "        var_name=\"pid\", value_name=\"employment\"\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 24\n",
    "eu_ue_df = pd.DataFrame(\n",
    "    {\n",
    "        \"dt\": pd.date_range(\"2019-01-01\", periods=T, freq=\"MS\"), \n",
    "        \"alpha\": np.ones(T)*0.25,\n",
    "        \"beta\": np.ones(T)*0.025\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pandas_employment_cross_section(eu_ue_df, np.array([0.25, 0.75]), N=500)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simulating the CPS**\n",
    "\n",
    "Rather than just simulate a full history for each person, we will simulate as if they were responses to the CPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting to a cross-section**\n",
    "\n",
    "We are going to continue using the \"frequency of transition\" idea that we previously proposed, but, we must account for the shape of the data we receive now.\n",
    "\n",
    "Let's think about the general case. Consider an $N$-state Markov chain. The parameters of the Markov chain are the elements of the transition matrix, $P$.\n",
    "\n",
    "$$P \\equiv \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\end{bmatrix}$$\n",
    "\n",
    "Let $\\{ \\{y_{i, 0}, y_{i, 1}, \\dots, y_{i, T_i}\\} \\; \\forall i \\in \\{0, 1, \\dots, I\\}\\}$ be a $I$ sequences of observations generated from the $N$-state Markov chain, then our new \"fitting\" procedure would assign the following value to $p_{ij}$:\n",
    "\n",
    "$$p_{ij} = \\frac{\\sum_{m=0}^I \\sum_{t=0}^T \\mathbb{1}_{y_{m, t} == i} \\mathbb{1}_{y_{m, t+1} == j}}{\\sum_{m=0}^I \\sum_{t=0}^T \\mathbb{1}_{y_{m, t} == i}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frequencies_cross_section(history):\n",
    "    \"\"\"\n",
    "    Computes the transition probabilities for a two-state\n",
    "    Markov chain\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    history : np.array(int, ndim=1)\n",
    "        An array with the state values of a two-state Markov chain\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    alpha : float\n",
    "        The probability of transitioning from state 0 to 1\n",
    "    beta : float\n",
    "        The probability of transitioning from state 1 to 0\n",
    "    \"\"\"\n",
    "    # Get length of the simulation and an index tracker\n",
    "    T = len(history)\n",
    "    idx = np.arange(T)\n",
    "\n",
    "    # Determine when the chain had values 0 and 1 -- Notice\n",
    "    # that we can't use the last value because we don't see\n",
    "    # where it transitions to\n",
    "    zero_idxs = idx[(history == 0) & (idx < T-1)]\n",
    "    one_idxs = idx[(history == 1) & (idx < T-1)]\n",
    "\n",
    "    # Check what percent of the t+1 values were 0/1\n",
    "    alpha = np.sum(history[zero_idxs+1]) / len(zero_idxs)\n",
    "    beta = np.sum(1 - history[one_idxs+1]) / len(one_idxs)\n",
    "\n",
    "    return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(T, alpha=0.25, beta=0.025):\n",
    "    \"\"\"\n",
    "    Checks the accuracy of our fit by printing the true values\n",
    "    and the fitted values for a given T\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    T : int\n",
    "        The length of our simulation\n",
    "    alpha : float\n",
    "        The probability that an individual goes from\n",
    "        unemployed to employed\n",
    "    beta : float\n",
    "        The probability that an individual goes from\n",
    "        employed to unemployed\n",
    "    \"\"\"\n",
    "    idx = np.arange(T)\n",
    "    alpha_np = np.ones(T)*alpha\n",
    "    beta_np = np.ones(T)*beta\n",
    "\n",
    "    # Simulate a sample history\n",
    "    emp_history = simulate_employment_history(alpha_np, beta_np, 0)\n",
    "\n",
    "    # Check the fit\n",
    "    alpha_hat, beta_hat = count_frequencies_individual(emp_history)\n",
    "    \n",
    "    print(f\"True alpha was {alpha} and fitted value was {alpha_hat}\")\n",
    "    print(f\"True beta was {beta} and fitted value was {beta_hat}\")\n",
    "    \n",
    "    return alpha, alpha_hat, beta, beta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Simulating the CPS**\n",
    "\n",
    "Recall that the CPS is generated by interviewing an individual for four consecutive months, having no interviews for 8 months, and then interviewing for four additional months.\n",
    "\n",
    "We will write code that allows us to simulate fake panels of CPS data which we will use to do similar exercises "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def single_individual(eu_ue_df, pid, s_0):\n",
    "    \"\"\"\n",
    "    Simulate a single individual's experience while in\n",
    "    a fake CPS sample\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eu_ue_df : pd.DataFrame\n",
    "        A DataFrame with columns `dt`, `alpha`, and `lambda`\n",
    "        that have the monthly eu/ue transition rates\n",
    "    s_0 : int\n",
    "        The initial state of unemployment/employment, which\n",
    "        should take value of 0 (unemployed) or 1 (employed)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.DataFrame\n",
    "        A DataFrame with the dates and an employment outcome\n",
    "        associated with each date of `eu_ue_df`\n",
    "    \"\"\"\n",
    "    # Make sure that `ue_ue_df` is sorted by date\n",
    "    eu_ue_df = eu_ue_df.sort_values(\"dt\")\n",
    "    _alpha = eu_ue_df[\"alpha\"].to_numpy()\n",
    "    _lambda = eu_ue_df[\"lambda\"].to_numpy()\n",
    "\n",
    "    # Simulate an individual\n",
    "    employment_history = simulate_employment_history(_alpha, _lambda, s_0)\n",
    "\n",
    "    # Combine into a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"pid\": pid,\n",
    "            \"dt\": eu_ue_df[\"dt\"],\n",
    "            \"employment\": employment_history\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eu_ue_df = pd.DataFrame(\n",
    "    {\n",
    "        \"dt\": pd.date_range(\"2020-01-01\", periods=24, freq=\"MS\"),\n",
    "        \"alpha\": 0.025,\n",
    "        \"lambda\": 0.25,\n",
    "    }\n",
    ")\n",
    "\n",
    "single_individual(eu_ue_df, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cps_single_individual(df, start_year, start_month):\n",
    "    \"\"\"\n",
    "    Takes a simulated individual and \"interviews\" them\n",
    "    according to the CPS schedule\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        A DataFrame with the columns `pid`, `dt`, and\n",
    "        `employment`\n",
    "    start_year : int\n",
    "        The year in which their interviewing begins\n",
    "    start_month : int\n",
    "        The month in which their interviewing begins\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cps : pd.DataFrame\n",
    "        A DataFrame with the same columns as `df` but only\n",
    "        with observations that correspond to the CPS\n",
    "        interview schedule for someone who starts\n",
    "        interviewing in f`{start_year}/{start_month}`\n",
    "    \"\"\"\n",
    "    # Get dates that are associated with being interviewed in\n",
    "    # the CPS\n",
    "    start_date_y1 = dt.datetime(start_year, start_month, 1)\n",
    "    dates_y1 = pd.date_range(start_date_y1, periods=4, freq=\"MS\")\n",
    "    start_date_y2 = dt.datetime(start_year+1, start_month, 1)\n",
    "    dates_y2 = pd.date_range(start_date_y2, periods=4, freq=\"MS\")\n",
    "    dates = dates_y1.append(dates_y2)\n",
    "\n",
    "    # Filter data that's not in the dates\n",
    "    cps = df.loc[df[\"dt\"].isin(dates), :]\n",
    "\n",
    "    return cps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "cps_single_individual(single_individual(eu_ue_df, 0, 0), 2020, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Unemployment Lecture**\n",
    "\n",
    "* A (finite) Markov chain of unemployment\n",
    "  - Describe simple model (that they briefly saw with Tom)\n",
    "  - Talk about how we could use this process to simulate a version of the CPS data\n",
    "  - Write code to do the simulation and store in a pandas DataFrame\n",
    "* Building up to the Lake model\n",
    "  - Estimate the probability associated with EU and UE\n",
    "  - How do these estimates change as we increase the number of individuals in our economy?\n",
    "  - Present the Lake model as what happens when we make each individual \"infinitely small\"\n",
    "* Economic experiments\n",
    "  - Go back to the graphs we made using the BLS data\n",
    "  - Extract the transition rates from the data\n",
    "  - Perform experiments... Answer questions like, if the rates went back to pre-COVID levels, how long until we reached pre-COVID levels of employment/unemployment?\n",
    "\n",
    "**Want**: Given current trends in the US labor market, how long until the economy has \"recovered\"? We will measure this as the economy reaching the pre-COVID levels of employment/unemployment.\n",
    "\n",
    "**Steps (from last to first)**\n",
    "\n",
    "- Use EU/UE transition rates to forecast employment/unemployment into the future to find when employment/unemployment reach pre-COVID levels\n",
    "- Forecast EU/UE transition rates into the future\n",
    "- Develop a simulatable model of employment/unemployment that output employment/unemployment\n",
    "- Use BLS data to determine pre-COVID levels of employment/unemployment and the history of EU/UE transition rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![employed_unemployed](employed_unemployed.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BLS Data\n",
    "\n",
    "We have already seen how to download and manipulate the BLS data on employment/unemployment, so we take it as given in this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "bls = pd.read_csv(\"bls_clean.csv\", parse_dates=[\"dt\"])\n",
    "\n",
    "pre_covid_employment = (\n",
    "    bls.query(\"variable == 'employed'\")\n",
    "       .loc[bls[\"dt\"].dt.year == 2019, \"value\"]\n",
    "       .mean()\n",
    ")\n",
    "pre_covid_unemployment = (\n",
    "    bls.query(\"variable == 'unemployed'\")\n",
    "       .loc[bls[\"dt\"].dt.year == 2019, \"value\"]\n",
    "       .mean()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "eu_ue_df = (\n",
    "    bls.pivot(index=\"dt\", columns=\"variable\", values=\"value\")\n",
    "       .assign(eu=lambda x: x[\"eu\"]/x[\"employed\"], ue=lambda x: x[\"ue\"]/x[\"unemployed\"])\n",
    "       .loc[\"2018-01-01\":, [\"eu\", \"ue\"]]\n",
    "       .rename(columns={\"eu\": \"alpha\", \"ue\": \"lambda\"})\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "eu_ue_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
